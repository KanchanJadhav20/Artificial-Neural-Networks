{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Adft8-cfJQXc"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The MNIST dataset is a widely-used benchmark dataset in the field of machine learning and computer vision. It consists of a collection of 28x28 pixel grayscale images of handwritten digits (0 through 9) along with their corresponding labels. This dataset is often used for tasks such as image classification and digit recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQZ4CYVTJU1q"
   },
   "source": [
    "# Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8867,
     "status": "ok",
     "timestamp": 1710959771470,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "_6VWZAIaJD3n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgSJXW3xJoCO"
   },
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1710959807178,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "6cm2ABHxJrHO",
    "outputId": "9085c4ae-0002-4f7f-f4aa-b2f43df20f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjyVOJp-JHhi"
   },
   "source": [
    "Let us check the dataset once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1710959833512,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "F6DCBpGxJvM_",
    "outputId": "476508fb-5521-4cbc-e8db-5967c845b758"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1710959843627,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "ETrV5ddEJws1",
    "outputId": "ec87af5a-e36f-4928-9130-e64d403db0a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1710959854006,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "sxksR8BXJ1JT",
    "outputId": "c14cddc9-0f31-443a-e3ac-11e5f64cec9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1710959861664,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "VoJuT-GlJ3xB",
    "outputId": "0ee2e115-8f7f-4145-b00d-db7b91d41194"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1710959897903,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "EnKPZt7eJ5oe",
    "outputId": "0ee85de4-d4e1-4fe8-e2f9-c106be0b5c72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Test data shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of the arrays\n",
    "print(\"Training data shape:\", x_train.shape)  # Shape of training images\n",
    "print(\"Training labels shape:\", y_train.shape)  # Shape of training labels\n",
    "print(\"Test data shape:\", x_test.shape)  # Shape of test images\n",
    "print(\"Test labels shape:\", y_test.shape)  # Shape of test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyWWf3VOKIPz"
   },
   "source": [
    "# Normalizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDVGB1YFKLc0"
   },
   "source": [
    "Min Max scaler has been used to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1710959944633,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "jJupJOROKCby"
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68g2WIrfKRZD"
   },
   "source": [
    "# Flattening the images for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1710959968564,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "7kDaz6a7KNuT"
   },
   "outputs": [],
   "source": [
    "# Flatten images\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1710959997134,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "GF8bwRy_KTv8",
    "outputId": "0ba4511b-af2b-4efb-dfb0-a9217000b71d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened training data shape: (60000, 784)\n",
      "Flattened test data shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of the flattened arrays\n",
    "print(\"Flattened training data shape:\", x_train_flat.shape)  # Shape of flattened training images\n",
    "print(\"Flattened test data shape:\", x_test_flat.shape)  # Shape of flattened test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlrZ5G17Kivj"
   },
   "source": [
    "So, we see now that we will have 784 neurons in the input layers. Let us process this ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMHvZGuDLY_K"
   },
   "source": [
    "# One hot encoding of the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkNZdlDDLb2N"
   },
   "source": [
    "In the case of the MNIST dataset, where each image represents a handwritten digit from 0 to 9, one-hot encoding converts the single scalar label for each image (which represents the digit) into a binary vector of length 10. Each element in this vector corresponds to a possible digit label, with a value of 1 indicating the presence of that digit and 0 otherwise.\n",
    "\n",
    "For example, if we have an input image of the digit 3, its corresponding one-hot encoded label would be [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].\n",
    "\n",
    "The length of this one-hot encoded vector matches the number of neurons in the input layer of the neural network. In this case, there would be 10 neurons in the input layer, each representing one possible digit label.\n",
    "\n",
    "During the training process, the neural network receives these one-hot encoded vectors as input, allowing it to learn the relationships between the features of the input images and their corresponding digit labels.\n",
    "\n",
    "## Why sparse in One Hot Encoding?\n",
    "If sparse=True, it returns a sparse binary matrix representation of the input labels. This means that instead of returning a dense array with one-hot encoding, it returns a sparse matrix where only the non-zero elements are stored. This is useful when dealing with large datasets with many classes, as it saves memory by not storing all the zeros in the dense representation. However, for most use cases, the default value of False suffices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1710960541740,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "bwfe1_UQKa0Z"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_onehot = onehot_encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_onehot = onehot_encoder.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1710960543659,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "O8WwKExSMS7X",
    "outputId": "a3963b40-79d8-437c-af7c-592769a805bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one-hot encoded training labels: (60000, 10)\n",
      "Shape of one-hot encoded testing labels: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of one-hot encoded training labels:\", y_train_onehot.shape)\n",
    "print(\"Shape of one-hot encoded testing labels:\", y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbhhXuTWMmw3"
   },
   "source": [
    "# Defining the ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_ck82Y5NuN7"
   },
   "source": [
    "`layers.Dense` refers to a fully connected layer. A fully connected layer is a type of neural network layer where each neuron in the layer is connected to every neuron in the preceding layer.\n",
    "\n",
    "`layers.Dropout` is a regularization technique commonly used in neural networks to prevent overfitting. Overfitting occurs when a model learns to memorize the training data rather than generalize well to new, unseen data.\n",
    "\n",
    "The Dropout layer works by randomly setting a fraction of input units to zero during training, which effectively \"drops out\" those units temporarily. This means that the units (neurons) in the Dropout layer do not contribute to the forward pass or backpropagation during training with a certain probability. By randomly dropping out units, Dropout introduces noise to the network, which helps prevent the network from relying too heavily on any particular set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1710960944012,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "2hCw5o_cMV8e"
   },
   "outputs": [],
   "source": [
    "# Define ANN model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(784,)),  # Input layer with 784 neurons and ReLU activation\n",
    "    layers.Dropout(0.2),  # Dropout layer to prevent overfitting\n",
    "    layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes) and softmax activation\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7K565luOKSF"
   },
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G69OMfHCOdqG"
   },
   "source": [
    "Compiling the model in the context of neural networks, specifically in frameworks like TensorFlow or Keras, involves configuring the model for training. When you compile a model, you specify several parameters that are necessary for training, including:\n",
    "\n",
    "**Optimizer:** This is the algorithm used to update the weights of the neural network based on the training data. Common choices include Stochastic Gradient Descent (SGD), Adam, RMSprop, etc. Each optimizer has its own set of hyperparameters that can be tuned.\n",
    "\n",
    "**Loss Function:** The loss function measures how well the model performs on the training data by comparing the predicted output with the actual target output. It represents the objective that the model aims to minimize during training. The choice of loss function depends on the type of problem you're solving (e.g., binary classification, multi-class classification, regression) and the nature of your data.\n",
    "\n",
    "**Metrics:** Metrics are used to monitor the performance of the model during training and evaluation. Common metrics for classification tasks include accuracy, precision, recall, F1-score, etc. For regression tasks, metrics like Mean Squared Error (MSE) or Mean Absolute Error (MAE) are often used.\n",
    "\n",
    "When you compile the model, you specify these components using appropriate arguments. Once the model is compiled, it's ready to be trained on the training data using the specified optimizer, loss function, and metrics.\n",
    "\n",
    "**Backpropagation** is used implicitly during the training phase in the code provided. When you train a neural network model using frameworks like TensorFlow, backpropagation is automatically handled for you by the optimization algorithm (e.g., stochastic gradient descent, Adam, etc.) that you choose when compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1710961265451,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "v9ZYJFSlOLya"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX2Vf2T5PRWt"
   },
   "source": [
    "The Adam optimizer is a popular optimization algorithm used for training deep learning models. It is an extension of the stochastic gradient descent (SGD) algorithm, which computes adaptive learning rates for each parameter by maintaining two moving averages of the gradients: the first moment (mean) and the second moment (uncentered variance).\n",
    "\n",
    "Here are some key characteristics of the Adam optimizer:\n",
    "\n",
    "**Adaptive Learning Rate:** Adam adjusts the learning rate for each parameter based on the magnitude of its gradients and the history of past gradients. This adaptivity helps in effectively navigating the loss landscape and converging faster, especially in cases where the gradients have varying magnitudes.\n",
    "\n",
    "**Bias Correction:** Adam performs bias correction to counteract the initialization bias and ensure that the estimated moments are unbiased, particularly at the beginning of training when the moving averages are initialized to zero.\n",
    "\n",
    "**Parameter Updates:** It computes individual adaptive learning rates for each parameter, which are used to update the parameters in the direction that minimizes the loss function.\n",
    "\n",
    "**Momentum:** Adam incorporates momentum similar to SGD with momentum, which helps accelerate convergence by accumulating gradients from previous time steps.\n",
    "\n",
    "**Regularization:** Adam includes built-in L2 weight decay regularization, which penalizes large weights and helps prevent overfitting.\n",
    "\n",
    "The Adam optimizer is widely used in various deep learning tasks due to its effectiveness and ease of use. It typically offers good performance across different types of neural network architectures and datasets, making it a popular choice for many researchers and practitioners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Qb0z6lCPxR2"
   },
   "source": [
    "**Categorical cross-entropy** is a loss function used in multi-class classification tasks, where the target variable (i.e., the true labels) is categorical and can take on more than two possible classes. It measures the dissimilarity between the true probability distribution of the classes and the predicted probability distribution output by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trkgk9sTQX0A"
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1710961638023,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "tqV832-uQj_7"
   },
   "outputs": [],
   "source": [
    "# Split training data into training and validation sets\n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(x_train_flat, y_train_onehot, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoK_KkaqRQXm"
   },
   "source": [
    "**Epoch:**\n",
    "An epoch refers to one complete pass through the entire training dataset. During one epoch, the model sees each training example once and updates its parameters (weights and biases) accordingly to minimize the chosen loss function. Training for multiple epochs allows the model to learn complex patterns from the data by adjusting its parameters iteratively. Typically, the number of epochs is a hyperparameter that needs to be specified by the user based on experimentation and observing the model's performance on a validation set.\n",
    "\n",
    "**Batch Size:** Batch size refers to the number of training examples utilized in one iteration. Instead of updating the model's parameters based on the gradients computed from the entire dataset (as in batch gradient descent), batch size determines how many examples are processed at once before updating the parameters. A smaller batch size results in more frequent updates to the model's parameters but can increase training time, while a larger batch size can speed up training but may lead to less accurate updates. Choosing an appropriate batch size involves balancing computational efficiency and model performance. Common batch sizes range from 8 to 256, depending on the dataset size and computational resources.\n",
    "\n",
    "In summary, during neural network training:\n",
    "\n",
    "* Epochs control the number of times the entire dataset is passed forward and backward through the neural network.\n",
    "* Batch size determines how many training examples are processed simultaneously before updating the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43451,
     "status": "ok",
     "timestamp": 1710961693485,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "L-utyrhkPQSy",
    "outputId": "fdc0430f-4aa5-4ed7-b0d4-30913c3227f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 6s 11ms/step - loss: 0.4410 - accuracy: 0.8729 - val_loss: 0.2298 - val_accuracy: 0.9363\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2160 - accuracy: 0.9378 - val_loss: 0.1691 - val_accuracy: 0.9521\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1641 - accuracy: 0.9524 - val_loss: 0.1361 - val_accuracy: 0.9611\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1336 - accuracy: 0.9608 - val_loss: 0.1162 - val_accuracy: 0.9665\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1162 - accuracy: 0.9656 - val_loss: 0.1052 - val_accuracy: 0.9693\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0991 - accuracy: 0.9707 - val_loss: 0.0989 - val_accuracy: 0.9705\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0872 - accuracy: 0.9740 - val_loss: 0.0912 - val_accuracy: 0.9733\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0787 - accuracy: 0.9758 - val_loss: 0.0841 - val_accuracy: 0.9752\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0713 - accuracy: 0.9783 - val_loss: 0.0804 - val_accuracy: 0.9762\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0639 - accuracy: 0.9803 - val_loss: 0.0828 - val_accuracy: 0.9772\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "img_model = model.fit(x_train_split, y_train_split, epochs=10, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTrmc2RkR5wS"
   },
   "source": [
    "# Evaluating the model on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEd36D8-URaP"
   },
   "source": [
    "`model.evaluate(x_test_flat, y_test_onehot)`: This function evaluates the model on the test data (`x_test_flat`) and corresponding true labels (`y_test_onehot`). It computes the loss and any other metrics specified during the compilation of the model. In this case, it calculates the loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3334,
     "status": "ok",
     "timestamp": 1710962099983,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "jk4qNLbSQuUS",
    "outputId": "c9f62d2d-f487-4ad2-c919-b34ccef88b41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0785 - accuracy: 0.9758\n",
      "Test Accuracy: 0.9757999777793884\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flat, y_test_onehot)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emTwx4FQSxxV"
   },
   "source": [
    "# Predicting on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3100,
     "status": "ok",
     "timestamp": 1710962213983,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "BHnxQcyrSC1W",
    "outputId": "a1bb09a8-8784-43f1-c726-a096fb75fbe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1710962317900,
     "user": {
      "displayName": "Yogesh Narayan Singh",
      "userId": "07246958582944678837"
     },
     "user_tz": -330
    },
    "id": "Lue4eG58S3Ne",
    "outputId": "f069682b-f485-443d-e51f-a7af1584a33b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0757532e-07, 4.0014578e-09, 1.1442638e-06, ..., 9.9962610e-01,\n",
       "        3.2582109e-05, 1.1780765e-04],\n",
       "       [1.9341680e-08, 1.4482893e-04, 9.9979210e-01, ..., 2.2339750e-13,\n",
       "        2.0373584e-05, 2.3300431e-10],\n",
       "       [1.3315276e-06, 9.9848735e-01, 2.5100767e-04, ..., 6.2476232e-04,\n",
       "        4.4810868e-04, 6.8912045e-06],\n",
       "       ...,\n",
       "       [9.8724355e-11, 9.8095609e-10, 3.5479525e-10, ..., 1.2193240e-06,\n",
       "        9.5068835e-06, 2.6077894e-04],\n",
       "       [5.4147414e-08, 3.3857582e-08, 3.2052776e-12, ..., 1.9250338e-08,\n",
       "        8.8209449e-04, 2.5835329e-08],\n",
       "       [9.8873011e-07, 1.5431493e-11, 2.5710563e-07, ..., 2.0438418e-11,\n",
       "        6.3097270e-09, 4.7623028e-10]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMu6vWyWkshBdrptlKgbodW",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
